# =============================================================================
# DOPPELGANGER TRACKER - Environment Configuration
# =============================================================================
# Copy this file to .env and configure your settings
# Run ./setup.sh for automated configuration
# =============================================================================

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================

# Application name displayed in logs and dashboard
APP_NAME=Doppelganger Tracker

# Enable debug mode (verbose logging, detailed error traces)
# Values: true, false
DEBUG=false

# Logging level for application output
# Values: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# =============================================================================
# DATABASE CONFIGURATION (PostgreSQL)
# =============================================================================

# PostgreSQL connection settings
# Note: For Docker deployment, use 'postgres' as POSTGRES_HOST (service name)
#       For local development, use 'localhost'

POSTGRES_USER=doppelganger
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_DB=doppelganger

# Host configuration
# Docker: postgres (service name in docker-compose.yml)
# Local: localhost or 127.0.0.1
POSTGRES_HOST=localhost
POSTGRES_PORT=5432

# Full database URL (alternative to individual settings above)
# Automatically constructed in Docker from individual variables
# Format: postgresql://user:password@host:port/database
# DATABASE_URL=postgresql://doppelganger:your_secure_password_here@localhost:5432/doppelganger

# =============================================================================
# REDIS CONFIGURATION
# =============================================================================

# Redis connection URL for caching and session management
# Docker: redis://redis:6379/0 (service name)
# Local: redis://localhost:6379/0
REDIS_URL=redis://localhost:6379/0

# =============================================================================
# TELEGRAM API CONFIGURATION
# =============================================================================

# Telegram API credentials for collecting from Telegram channels
# Get your credentials from: https://my.telegram.org/apps
#
# Steps to obtain credentials:
# 1. Visit https://my.telegram.org/apps
# 2. Log in with your phone number
# 3. Create a new application
# 4. Copy the 'api_id' and 'api_hash'
#
# IMPORTANT: Leave empty to disable Telegram collection
# The collector will skip Telegram if these are not configured

TELEGRAM_API_ID=
TELEGRAM_API_HASH=

# Telegram session file name (stored in /app/.sessions in Docker)
# Change this if running multiple instances
TELEGRAM_SESSION_NAME=doppelganger_collector

# =============================================================================
# COLLECTION SETTINGS
# =============================================================================

# Interval between collection runs (in seconds)
# Default: 300 (5 minutes)
# Recommended: 300-600 for production, 60-120 for testing
COLLECTION_INTERVAL=300

# Number of days to look back on initial collection
# Default: 7 days
# Note: Large values may take longer on first run
INITIAL_LOOKBACK_DAYS=7

# Maximum messages to collect per Telegram channel per run
# Default: 100
# Note: Higher values increase memory usage
MAX_MESSAGES_PER_CHANNEL=100

# HTTP request timeout for RSS feeds and web scraping (in seconds)
# Default: 30 seconds
REQUEST_TIMEOUT=30

# =============================================================================
# ANALYSIS SETTINGS
# =============================================================================

# Number of content items to process per NLP batch
# Default: 500
# Note: Higher values use more memory but are faster
# Recommended: 100-500 for 4GB RAM, 500-1000 for 8GB+ RAM
NLP_BATCH_SIZE=500

# Number of days to analyze for network analysis
# Default: 30 days
# Note: Larger values increase computation time
NETWORK_LOOKBACK_DAYS=30

# Minimum similarity threshold for content propagation detection
# Range: 0.0 to 1.0 (0 = no similarity, 1 = identical)
# Default: 0.5 (50% similarity)
# Recommended: 0.4-0.6 for disinformation detection
MIN_SIMILARITY_THRESHOLD=0.5

# Confidence threshold for propaganda technique detection
# Range: 0.0 to 1.0
# Default: 0.7 (70% confidence)
# Higher values = fewer false positives, may miss some propaganda
PROPAGANDA_THRESHOLD=0.7

# =============================================================================
# DIRECTORY PATHS
# =============================================================================

# Local development paths (relative to project root)
# Note: In Docker, these are mapped to container paths in docker-compose.yml

# Directory for collected data and temporary files
DATA_DIR=./data

# Directory for application logs
LOGS_DIR=./logs

# Directory for analysis exports (graphs, reports, CSV)
EXPORTS_DIR=./exports

# Directory for configuration files (sources.yaml, keywords.yaml, etc.)
CONFIG_DIR=./config

# =============================================================================
# DOCKER-SPECIFIC SETTINGS (Optional)
# =============================================================================

# Dashboard port (exposed on host)
# Default: 8501
# Change this if port 8501 is already in use
# DASHBOARD_PORT=8501

# =============================================================================
# ADVANCED SETTINGS (Optional - Use Defaults)
# =============================================================================

# Streamlit server configuration (for dashboard)
# STREAMLIT_SERVER_PORT=8501
# STREAMLIT_SERVER_ADDRESS=0.0.0.0

# APScheduler settings for collection scheduling
# SCHEDULER_TIMEZONE=UTC

# Database connection pool settings
# DB_POOL_SIZE=5
# DB_MAX_OVERFLOW=10
# DB_POOL_TIMEOUT=30

# =============================================================================
# NOTES
# =============================================================================
#
# 1. Security:
#    - Never commit .env to version control
#    - Use strong passwords for production
#    - Rotate Telegram API credentials regularly
#
# 2. Docker Deployment:
#    - Use service names (postgres, redis) for hosts
#    - Volumes persist data across container restarts
#    - Use docker-compose logs to debug connection issues
#
# 3. Performance Tuning:
#    - Increase NLP_BATCH_SIZE for faster processing (requires more RAM)
#    - Decrease COLLECTION_INTERVAL for real-time monitoring
#    - Adjust NETWORK_LOOKBACK_DAYS based on data volume
#
# 4. Telegram Collection:
#    - First run requires interactive phone verification
#    - Session persists in telegram_sessions volume
#    - Monitor rate limits (avoid very low COLLECTION_INTERVAL)
#
# =============================================================================
