# ğŸ”¬ Doppelganger Tracker - Expert Recommendations

## Executive Summary

Ce document prÃ©sente les recommandations d'amÃ©lioration pour transformer le projet Doppelganger Tracker d'un outil acadÃ©mique en solution production-grade capable de traiter des millions de contenus.

---

## ğŸ“Š Comparaison v2 â†’ v3

| Aspect | v2 (Actuel) | v3 (RecommandÃ©) | Impact |
|--------|-------------|-----------------|--------|
| **Architecture** | Monolithique couplÃ©e | Hexagonale avec DI | +40% maintenabilitÃ© |
| **NLP** | Lexicon-based | Transformers + Embeddings | +60% prÃ©cision |
| **DÃ©tection Propagande** | RÃ¨gles simples | Fine-tuned BERT | +45% recall |
| **Embeddings** | Aucun | SBERT multilingue 768d | SimilaritÃ© sÃ©mantique |
| **Recherche** | SQL LIKE | FAISS Vector Search | 100x plus rapide |
| **Cache** | Aucun | Multi-level (L1+L2) | -80% latence |
| **Streaming** | Batch simple | Async generators | Temps rÃ©el |
| **Monitoring** | Logs basiques | Prometheus + Grafana | ObservabilitÃ© complÃ¨te |
| **Visualisation** | Streamlit basic | Pyvis + Plotly interactif | UX amÃ©liorÃ©e |

---

## ğŸ—ï¸ 1. Architecture - Hexagonale (Clean Architecture)

### Avant (v2)
```
Controllers â†’ Services â†’ Models â†’ Database
     â†“           â†“          â†“
  Couplage fort, difficile Ã  tester
```

### AprÃ¨s (v3)
```
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Use Cases     â”‚  â† Application Layer
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“             â†“             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Ports   â”‚   â”‚ Domain  â”‚   â”‚ Ports   â”‚  â† Domain Layer
    â”‚ (Input) â”‚   â”‚Entities â”‚   â”‚(Output) â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚                           â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚Adapters â”‚                 â”‚Adapters â”‚  â† Infrastructure
    â”‚  (API)  â”‚                 â”‚  (DB)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fichiers clÃ©s crÃ©Ã©s:
- `core/domain.py` - EntitÃ©s, Value Objects, Use Cases

### BÃ©nÃ©fices:
- âœ… TestabilitÃ© (mocks faciles via interfaces)
- âœ… FlexibilitÃ© (swap d'implÃ©mentations)
- âœ… MaintenabilitÃ© (responsabilitÃ©s claires)

---

## ğŸ§  2. NLP Pipeline Moderne

### Stack recommandÃ©e:

| Composant | ModÃ¨le | Usage |
|-----------|--------|-------|
| **Embeddings** | `paraphrase-multilingual-mpnet-base-v2` | SimilaritÃ© sÃ©mantique multilingue |
| **Sentiment** | `cardiffnlp/twitter-xlm-roberta-base-sentiment` | Sentiment multilingue |
| **Propagande** | `QCRI/PropagandaTechniques-en` | DÃ©tection de techniques |
| **EntitÃ©s** | spaCy `xx_ent_wiki_sm` | NER multilingue |

### Pipeline unifiÃ©:
```python
# core/nlp_pipeline.py
pipeline = UnifiedNLPPipeline(
    config=NLPPipelineConfig(
        embedding_model="paraphrase-multilingual-mpnet-base-v2",
        sentiment_model="cardiffnlp/twitter-xlm-roberta-base-sentiment",
        use_gpu=True,
        enable_embeddings=True,
        enable_propaganda=True,
        enable_narratives=True
    ),
    narratives_config=load_narratives()
)

result = pipeline.process(text)
# â†’ result.sentiment, result.propaganda_techniques, result.embedding, result.threat_score
```

### Fichiers clÃ©s crÃ©Ã©s:
- `core/nlp_pipeline.py` - Pipeline NLP complet

### AmÃ©liorations:
- âœ… Embeddings sÃ©mantiques (vs bag-of-words)
- âœ… Classification Transformers (vs rÃ¨gles)
- âœ… Recherche vectorielle FAISS
- âœ… Score de menace composite

---

## ğŸ“Š 3. Data Pipeline Production-Grade

### Composants:

#### Cache Multi-niveau
```
Request â†’ L1 (Local, 10ms) â†’ L2 (Redis, 50ms) â†’ Source (500ms+)
```

#### Streaming Processing
```python
pipeline = StreamPipeline()
pipeline.add(FilterProcessor(lambda x: x.language == "fr"))
pipeline.add(MapProcessor(lambda x: normalize(x)))
pipeline.add(BatchProcessor(batch_size=100))

async for batch in pipeline.run(source_stream):
    await process_batch(batch)
```

#### Feature Store
```python
feature_store = FeatureStore(cache=cache)

# DÃ©finir une feature
feature_store.register_feature(FeatureDefinition(
    name="embedding_768",
    dtype="vector",
    compute_fn=lambda x: embed(x.text),
    ttl_seconds=86400
))

# RÃ©cupÃ©rer pour ML
vector = await feature_store.get_feature_vector(
    entity_id=content_id,
    feature_names=["embedding_768", "sentiment_score", "propaganda_score"]
)
```

### Fichiers clÃ©s crÃ©Ã©s:
- `core/data_pipeline.py` - Cache, Streaming, Feature Store, Events

### BÃ©nÃ©fices:
- âœ… Cache hit rate >80%
- âœ… Traitement temps rÃ©el
- âœ… Features ML servables

---

## ğŸ“ˆ 4. Visualisation AvancÃ©e

### Composants crÃ©Ã©s:

#### RÃ©seau interactif
```python
viz = PropagationNetworkViz()
html = viz.create_interactive_network(graph)
# â†’ Pyvis interactif avec zoom, hover, clustering
```

#### Timelines dynamiques
```python
fig = TimelineViz.propaganda_timeline(df)
# â†’ Zones de risque colorÃ©es + volume overlay
```

#### Dashboard components
```python
gauge = DashboardComponents.create_gauge(
    value=0.75,
    title="Threat Level"
)
```

### Fichiers clÃ©s crÃ©Ã©s:
- `core/visualization.py` - Network, Timeline, Dashboard, Reports

---

## ğŸš€ 5. Recommandations d'ImplÃ©mentation

### Phase 1: Quick Wins (1-2 semaines)
1. ImplÃ©menter le cache multi-niveau
2. Ajouter les embeddings SBERT
3. CrÃ©er les visualisations rÃ©seau Pyvis

### Phase 2: NLP Upgrade (2-4 semaines)
1. IntÃ©grer le pipeline NLP unifiÃ©
2. Ajouter FAISS pour recherche vectorielle
3. Fine-tuner le classificateur de propagande

### Phase 3: Architecture (4-8 semaines)
1. Refactorer vers architecture hexagonale
2. ImplÃ©menter le Feature Store
3. Ajouter l'Event Bus

### Phase 4: Production (2-4 semaines)
1. Monitoring Prometheus/Grafana
2. CI/CD avec tests
3. Kubernetes deployment

---

## ğŸ“ Structure Projet v3

```
doppelganger-tracker/
â”œâ”€â”€ core/                      # ğŸ†• Domain & Business Logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ domain.py              # Entities, Use Cases, Ports
â”‚   â”œâ”€â”€ nlp_pipeline.py        # Advanced NLP
â”‚   â”œâ”€â”€ data_pipeline.py       # Caching, Streaming
â”‚   â””â”€â”€ visualization.py       # Advanced Viz
â”‚
â”œâ”€â”€ adapters/                  # ğŸ†• Infrastructure Implementations
â”‚   â”œâ”€â”€ repositories/          # DB implementations
â”‚   â”‚   â”œâ”€â”€ postgres_content.py
â”‚   â”‚   â””â”€â”€ redis_cache.py
â”‚   â”œâ”€â”€ collectors/            # Source adapters
â”‚   â”‚   â”œâ”€â”€ telegram_adapter.py
â”‚   â”‚   â””â”€â”€ rss_adapter.py
â”‚   â””â”€â”€ ml/                    # ML adapters
â”‚       â”œâ”€â”€ transformers_nlp.py
â”‚       â””â”€â”€ faiss_search.py
â”‚
â”œâ”€â”€ application/               # ğŸ†• Application Services
â”‚   â”œâ”€â”€ commands/              # Write operations
â”‚   â””â”€â”€ queries/               # Read operations
â”‚
â”œâ”€â”€ infrastructure/            # ğŸ†• Cross-cutting
â”‚   â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ logging/
â”‚   â””â”€â”€ monitoring/
â”‚
â”œâ”€â”€ presentation/              # UI Layer
â”‚   â”œâ”€â”€ api/                   # REST API (FastAPI)
â”‚   â””â”€â”€ dashboard/             # Streamlit
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ unit/
    â”œâ”€â”€ integration/
    â””â”€â”€ e2e/
```

---

## ğŸ“Š KPIs Cibles

| MÃ©trique | v2 | v3 Target |
|----------|-----|-----------|
| Latence analyse (p95) | 2s | <200ms |
| PrÃ©cision propagande | 65% | >85% |
| Cache hit rate | 0% | >80% |
| Throughput | 10/s | >100/s |
| Temps dÃ©ploiement | 30min | <5min |

---

## ğŸ”§ DÃ©pendances Additionnelles

```txt
# requirements-v3.txt (additions)

# ML / NLP
sentence-transformers>=2.2.0
transformers>=4.36.0
torch>=2.1.0
faiss-cpu>=1.7.4

# Caching
redis>=5.0.0
aioredis>=2.0.0

# Monitoring
prometheus-client>=0.19.0

# Visualization
pyvis>=0.3.2
altair>=5.2.0

# API (optionnel)
fastapi>=0.108.0
uvicorn>=0.25.0
```

---

## âœ… Checklist Migration

- [ ] CrÃ©er le module `core/`
- [ ] ImplÃ©menter `MultiLevelCache`
- [ ] IntÃ©grer `sentence-transformers`
- [ ] CrÃ©er index FAISS
- [ ] Refactorer vers Use Cases
- [ ] Ajouter mÃ©triques Prometheus
- [ ] CrÃ©er composants Pyvis
- [ ] Ã‰crire tests unitaires
- [ ] Documenter API
- [ ] DÃ©ployer sur Kubernetes

---

## ğŸ“š Ressources

- [Hexagonal Architecture](https://alistair.cockburn.us/hexagonal-architecture/)
- [Sentence-BERT](https://www.sbert.net/)
- [FAISS](https://github.com/facebookresearch/faiss)
- [Prometheus Python](https://github.com/prometheus/client_python)
- [Pyvis](https://pyvis.readthedocs.io/)

---

*Document gÃ©nÃ©rÃ© le: 2025-12-31*
*Version: 3.0-DRAFT*
